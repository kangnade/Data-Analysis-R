shapiro.test(model1$residuals)
qqnorm(model1$residuals)
# Solution:
# Create shifted versions of education and experience, so that the person of interest
# scores a 0 in all explanatory variables
wage1$exper_5 <- wage1$exper - 5
wage1$expersq_5 <- wage1$exper_5*wage1$exper_5
wage1$educ_18 <- wage1$educ - 18
# We again, run the regression and save it in model2
model2 <- lm(log(wage)~exper_5 + expersq_5 + educ_18 + female + nonwhite, data = wage1)
summary(model2)
# to obtain the exponential of coefficients
exp(model2$coefficients)
1-0.7136061
# To get the prediction with log, we know that the intercept from the regression is:8.0318811, which is part A
A <- 8.0318811
B1 <- exp(0.4138^2/2) # the residual std. error
B1
predicted_wage <- A*B1
predicted_wage
# c) to get the prediction using Duan's (1983) approach
# B is the E[exp(u)|x]
B2 <- mean(exp(model2$residuals)) # Duan's (1983) approach
B2
predicted_wage2 <- A*B2
predicted_wage2
# To get the confidence interval:
exp(confint(model2))
# b) to test for normality: the Shapiro -Wilk Normality Test tests the Null Hypothesis
# that the residuals are normally distributed against the Alternative Hypothesis that the
# residuals are NOT normally distributed
shapiro.test(model1$residuals)
# The p-value is smaller than 0.05, which means that we have to reject the null hypothesis,
# that the residuals are not normally distributed.
# Let's use qqnorm to run the test
qqnorm(model1$residuals)
# The Q-Q plot shows a good straight line, which means the residuals are normally distributed
# Although the Q-Q plot does not agree with the Shapiro-test, it only means that the residuals
# are slightly non-normal, but generally normality can be assumed.
model3 <- lm(wage ~ exper + expersq + educ + female + nonwhite, data = wage1)
summary(model3)
skoda <- read.csv("http://nb.vse.cz/~zouharj/econ/skoda.csv")
# To fix the ugly numbers in the summary, do it once for all for this session
# . Scientific notation scipen
options(scipen = 5)
# change unit under km, but if we do so, we cannot use the priod to regress on everything else
skoda$km <- skoda$km/10000
# Run a regression of log(price) on everything else and test whether
# fuel type affects the price. Regress on everything else use period . to do so
# First run the regression
model1 <- lm(log(price) ~ ., data = skoda)
summary(model1)
# Omitted variable fuel: autogas
# If we want to understand does Fuel matter?
# We pick the H0: Beta-fuel|diesel| = 0, Beta-fuel|petrto| = 0
# So we need to test joint significance of Fuel Dummies (F test)
# Use base R without loading package to do F test
# Next, run the "restrictted" regression - without fuel
model1restricted <- lm(log(price) ~ km + year + combi + model, data = skoda)
# We run anova of model1 and model1restricted
# ANOVA implements an F-test
anova(model1, model1restricted)
# Neither of the two fuel variables are significant in model1 by usual standards on its own right
# In ANOVA, p < 0.05, so we reject the null hypothesis and conclude that "Fuel Matters"
# A different way to carry out the test
# Same test for joint significance
# We have to upload a new package called "car"
# install.packages("car")
library("car")
# This package has the following command
# linearyHypothesis(model, c("variables you want to omit-the dummies"))
linearHypothesis(model1, c("fueldiesel", "fuelpetrol"))
# The result states the null hypothesis
# In addition, let us test another type of a linear hypothesis:
# H0: Beta-year = Beta-combi
linearHypothesis(model1, "year = combi")
# NOTE: we cannot write c("year", "combi") here because this is testing:
# H0: Beta-year = 0, Beta-combi = 0. This is a totally different null hypothesis
# In addition, we can also do the followings with the linearHypothesis(which actually makes no sense)
# H0: Beta-year = Beta-combi, 2Beta-year + Beta-km = 5
linearHypothesis(model1, c("year = combi", "2*year + km = 5"))
# Again, this is only a demonstration of the powefulness of this function, but it makes no sense
# Change the reference fuel category from "autogas" to "petrol"
skoda$fuel <- relevel(skoda$fuel, ref="petrol")
# it becomes the first category to be eliminated if there are dummy variables
model2 <- lm(log(price) ~ ., data = skoda)
summary(model2)
# In the last two rows, fueldiesel is highly significant
# In the first model, model1, we would like to conlcude fuel is not important
# But here, we see one significant result from fuel, so we might conclude important
# So we see, that we could manupilate the categorical variables to get different result
# This is something we don't like
linearHypothesis(model2, c("fueldiesel", "fuelautogas"))
# run the test for joint significance
# p value exactly as in the linearHypothese test in model1
# Change of category, you can manipulate the results of the regression
# But the change of category doesn't influence the result of test for joint significance
# This can be proved using the Fisher's Model
# Now we use the stargazer package to produce a table for both of these regressions
library(stargazer)
stargazer(model1, model2, type ="text")
# To deal with Heteroskedasticity, we need two more packages
# install.packages("lmtest") # Tests of Homoskedasticity
# install.packages("sandwich") # Robust std. error
library(lmtest)
library(sandwich)
# Test of Homoskedasticity in model1 (caution: the test is weak!)
# Breusch-Pagan test
bptest(model1)
# Remember the null hypothesis is Homoskedasticity: H0: Homoskedasticity
# The result p-value is small, so we reject Homoskedasticity
# All the tests we did were not well, so all the previous hypothesis tests are invalid
# So what should we do?
# Robust standard errors will be based on: Heteroskedasticity consistent
vcov_robust <- vcovHC(model1)
stdErr_robust <- sqrt(diag(vcov_robust))
stdErr_robust
cor(residuals(model3), model3$model3$2)
cor(residuals(model3), model3$model3)
model3$coefficients
cor(model3$residuals, model3$coefficients)
cor(model3$residuals, method= c(model3$coefficients))
betas <- c(0.255445836, -0.004448147, 0.554631877, -2.115792505, -0.157832884)
cor(model3$residuals, betas)
cor(help)
help(cor)
residual <- model3$residuals
residualVector <- c(residual, residual, residual, residual, residual)
cor(residualVector, betas)
residual
cor(model3$residuals, model3$coefficients)
View(wage1)
residualM3 <- model3$residuals
residualM3
wage1$exper
cor(residualM3, wage1$exper)
bptest(model3)
library(GGally)
ggpairs(model3)
uhat <- model3$residuals
cor(dt[uhat, c("exper", "educ", "female", "nonwhite")])
cor(uhat, dt[c("exper", "educ", "female", "nonwhite")])
cor(dt[c("exper", "educ", "female", "nonwhite")], uhat)
cor(uhat, wage1[c("exper", "educ", "female", "nonwhite")])
# Question 2.3
model3 <- lm(wage ~ exper + expersq + educ + female + nonwhite, data = wage1)
summary(model3)
uhat <- model3$residuals
cor(uhat, wage1[c("exper", "educ", "female", "nonwhite")])
# Question 2.3
model3 <- lm(wage ~ exper + expersq + educ + female + nonwhite, data = wage1)
summary(model3)
uhat <- model3$residuals
cor(uhat, wage1[c("exper", "expersq", "educ", "female", "nonwhite")])
cor(model3$fitted.values, wage1$wage)
result <- cor(model3$fitted.values, wage1$wage)
result^2
wage1$wage2-hat <- exp(model1$fitted.values)*B2
B1 <- exp(0.4138^2/2) # the residual std. error
B1
B2 <- mean(exp(model2$residuals)) # Duan's (1983) approach
B2
wage1$wage2-hat <- exp(model1$fitted.values)*B2
wage1$wage2hat <- exp(model1$fitted.values)*B2
wage1$wage2hat <- exp(model1$fitted.values)*1.009537
cor(wage1$wage, wage1$wage2hat)
wage1$wage2hat <- exp(model1$fitted.values) * 1.009537
wage2hat <- exp(model1$fitted.values) * 1.009537
cor(wage1$wage, wage2hat)
wage2hat
library(utils)
utils::adist()
utils::adist(sitting, kitten)
x <- c(s,i,t,t,i,n,g)
x <- c("s,i,t,t,i,n,g")
x
y <- c("k,i,t,t,e,n")
utils::adist(x, ky)
utils::adist(x, y)
x <- "sitting"
x
y <- "kitten"
utils::adist(x, y)
help(utils::adist)
help(utils)
"utils"
help(adist)
utils::adist(x, y, costs = (1,1,2))
utils::adist(x, y, costs = c(1,1,2))
utils::adist(x, y, costs = list(i=1,d=1,s=2))
install.packages("TraMineR")
library(TraMineR)
library(gganimate)
library(httr)
set_config(config(ssl_verifypeer = 0L))
library(devtools)
library(RCurl)
library(httr)
set_config( config( ssl_verifypeer = 0L ) )
devtools::install_github("RcppCore/Rcpp")
devtools::install_github("dgrtwo/gganimate")
shareimprove this answer
library(bitops)
library(devtools)
library(gganimate)
library(devtools)
library(devtools)
library(RCurl)
library(httr)
install.packages("bitops")
install.packages("bitops")
library(devtools)
library(RCurl)
library(bitops)
library(RCurl)
library(httr)
library(gganimate)
gganimate::gganimate(p)
library(TraMineR)
seqdef(rbind("s-i-t-t-i-n-g","k-i-t-t-e-n"))
d1 <- seqdef(rbind("s-i-t-t-i-n-g","k-i-t-t-e-n"))
seqdist(d1, method = "OM", indel = 1, sm = "CONSTANT")
seqplot(d1)
dur <- read.csv("http://nb.vse.cz/~zouharj/econ/durgoods.csv")
head(dur)
plot(dur$dish)
plot(dur$dish, type = "b")
plot(dur$frig, type = "b")
dur$year <- seq(from=1978, to=1987.75, by=0.25)
dur$year <- seq(from=1978, to=1985.75, by=0.25)
plot(dur$frig ~ dur$year, type = "b")
dur$quarter <- 1:4
model1 <- lm(dish ~ quarter, data = dur)
summary(model1)
plot(dur$dish, type = "b")
line(model1$fitted.values)
plot(dur$dish, type = "b")
lines(model1$fitted.values)
dur$quarter <- factor(1:4)
model1 <- lm(dish ~ quarter, data = dur)
summary(model1)
plot(dur$dish, type = "b")
lines(model1$fitted.values)
model2 <- lm(frig ~ quarter, data = dur)
summary(model2)
model2 <- lm(frig ~ quarter, data = dur)
summary(model2)
plot(dur$frig, type = "'b")
lines(model2$fitted.values)
model2 <- lm(frig ~ quarter, data = dur)
summary(model2)
plot(dur$frig, type = "'b")
lines(model2$fitted.values)
plot(dur$frig, type = "'b")
lines(model2$fitted.values)
model2 <- lm(frig ~ quarter, data = dur)
summary(model2)
plot(dur$frig, type = "b")
lines(model2$fitted.values)
model3 <- lm(frig ~ quarter + year + I(year^2), data = dur)
summary(model3)
model3 <- lm(frig ~ quarter + year + I(year^2), data = dur) # if not creating new variable, use I() function to square
summary(model3)
plot(dur$frig, type = "b")
lines(model3$fitted.values)
plot(dur$frig, type = "b", xlab = "Quarter", ylab = "Sales of Fridges", main = "Seasonality of Fridges Sales")
plot(dur$frig, type = "b", xlab = "Quarter", ylab = "Sales of Fridges", main = "Seasonality of Fridges Sales")
lines(model3$fitted.values)
dur$frig_adjusted <- model3$residuals
plot(dur$frig_adjusted, type = "b")
dur$frig_adjusted <- model3$residuals + mean(dur$frig)
plot(dur$frig_adjusted, type = "b")
lines(dur$frig)
anova(model3, lm(frig ~ year + I(year^2), data = dur))
model4 <-- lm(log(frig) ~ quarter, data = dur)
summary(model4)
model4 <- lm(log(frig) ~ quarter, data = dur)
summary(model4)
exp(model4$coefficients) # To exponentiate and get the factors of multiplication
dt <- read.csv("http://nb.vse.cz/~zouharj/econ/fertil3.csv")
desc <- read.csv("http://nb.vse.cz/~zouharj/econ/fertil3_desc.csv")
View(desc)
head(dt)
head(dt, n=10)
head(dt[,c("pe","pe_1","")], n=10)
head(dt[,c("pe","pe_1","pe_2","pe_3")], n=10)
tail(dt[,c("pe","pe_1","pe_2","pe_3")], n=10)
head(dt[,c("year","pe","pe_1","pe_2","pe_3")], n=10)
tail(dt[,c("year","pe","pe_1","pe_2","pe_3")], n=10)
plot(dt$ww2, type = "b")
plot(dt$ww2 ~ dt$year, type = "b")
plot(dt$ww2 ~ dt$year, type = "b", xlab="Year", ylab="WW2")
model5 <- lm(gfr ~ year, data = dt)
summary(model5)
plot(gfr ~ year, data = dt, type = "b")
lines(model5$fitted.values)
plot(gfr ~ year, data = dt, type = "b", xlab = "Year", ylab = "General Fertility Rate", main = "Model 5 Fertility on Years")
plot(dt$gfr, type = "b", xlab = "Year", ylab = "General Fertility Rate", main = "Model 5 Fertility on Years")
lines(model5$fitted.values)
model6 <- lm(gfr ~ year + ww2 + pill, data=dt)
summary(model6)
model6 <- lm(gfr ~ year + ww2 + pill, data=dt)
summary(model6)
plot(dt$gfr, type = "b")
lines(model6$fitted.values)
plot(dt$gfr, type = "b", xlab = "Year", ylab = "General Fertility Rate", main = "Model 5 Fertility on Years")
lines(model6$fitted.values)
plot(dt$gfr, type = "b", xlab = "Year", ylab = "General Fertility Rate", main = "Model 6 Fertility on Years")
lines(model6$fitted.values)
model7 <- lm(gfr ~ year + ww2 + pill + pe + pe_1 + pe_2, data=dt)
summary(model7)
plot(dt$gfr, type = "b", xlab = "Year", ylab = "General Fertility Rate", main = "Model 7 Fertility on Years")
lines(model7$fitted.values)
anova(model6, model7) # F-test for pe, pe_1, and pe_2
model6_fix <- lm(gfr ~ year + ww2 + pill, data=dt[-c(1,2),])
summary(model6_fix)
plot(dt$gfr, type = "b", xlab = "Year", ylab = "General Fertility Rate", main = "Model 6_fix Fertility on Years")
lines(model6_fix$fitted.values)
anova(model6_fix, model7)
library(car)
library(car)
linearHypothesis(model7, c("pe","pe_1"."pe_2"))
linearHypothesis(model7, c("pe","pe_1","pe_2"))
okun2 <- read.csv("okun2.csv", sep = ";")
library(readr)
automobile_market <- read_csv("C:/Users/nade/Desktop/Intro Econometrics/Excel Data/automobile_market.csv")
View(automobile_market)
library(readr)
labour_market <- read_csv("C:/Users/nade/Desktop/Intro Econometrics/Excel Data/labour_market.csv")
View(labour_market)
at <- automobile_market
1990-1975
15*12
180+10
1/12
0.08333333*10
at$year <- seq(from=1975, to=1991.83333, by=0.083333)
at$year <- seq(from=1975.083333, to=1991.83333, by=0.083333)
head(at)
View(at)
at$month <- 1:12
at$month <- 1:12[-2]
View(at)
at$month <- seq(1:12,length.out = 202)
at$month <- 1:12
View(at)
help("seq")
help("repeated number")
help("month dummy")
help("repeat number")
help("seq_len")
at$month <- 1:12
automobile_market$month <- 1:12
at$month <- 1:12
dur <- read.csv("http://nb.vse.cz/~zouharj/econ/durgoods.csv")
dur$year <- seq(from=1978, to=1985.75, by=0.25)
at$month <- 1:12
help("seq_along")
at$month <- 1:12
at$month1 <- 1:12
help("rep")
at$month <- rep(1:12,202)
at$month <- rep(1:12)
at$month <- rep(1:12, length.out=202)
head(at)
View(at)
View(at)
model1 <- lm(log(carexp)~year + month, data = at)
summary(model1)
help(bgtest)
check1 <- lm(log(carexp)~year, data=at)
summary(check1)
model1 <- lm(log(carexp)~year + month, data = at)
summary(model1)
model2 <- lm(log(carexp)~month, data=at)
summary(model2)
anova(model1,model2)
model1 <- lm(log(carexp)~year + month, data = at)
summary(model1)
plot(at$carexp~at$year, type="b")
model3 <- lm(log(carexp)~year, data=at)
summary(model3)
anova(model1, model3)
library(car)
linearHypothesis(model1, "year")
linearHypothesis(model1, "month")
lag <- function(series){
n <- length(series)
lagged_series <- c(NA, series[-n])
return(lagged_series)
}
n <- nrow(at)
at$unemp_lag1 <- c(NA, at$unemp[-n])
at$unemp_lag2 <- c(NA, at$at$unemp_lag1[-n])
lag <- function(series){
n <- length(series)
lagged_series <- c(NA, series[-n])
return(lagged_series)
}
n <- nrow(at)
at$unemp_lag1 <- c(NA, at$unemp[-n])
at$unemp_lag2 <- c(NA, at$at$unemp_lag1[-n])
View(at)
lag <- function(series){
n <- length(series)
lagged_series <- c(NA, series[-n])
return(lagged_series)
}
n <- nrow(at)
at$unemp_lag1 <- c(NA, at$unemp[-n])
at$unemp_lag2 <- c(NA, at$unemp_lag1[-n])
View(at)
lm(log(carexp)~unemp + unemp_lag1 + unemp_lag2 + year, data=at)
q1d <- lm(log(carexp)~unemp + unemp_lag1 + unemp_lag2 + year, data=at)
summary(q1d)
options(scipen = 5)
q1d <- lm(log(carexp)~unemp + unemp_lag1 + unemp_lag2 + year, data=at)
summary(q1d)
exp(q1d$coefficients)
exp(q1d$coefficients)-1
at$carexp_adjusted <- model1$residuals
q1e <- lm(log(carexp_adjusted)~unemp + unemp_lag1 + unemp_lag2 + year, data=at)
summary(q1e)
q1f<-lm(unemp~unemp_lag1,data=at)
summary(q1f)
library(orcutt)
model_CO <- cochrane.orcutt(q1e)
summary(model_CO)
confint(model_CO$coefficients)
confint(model_CO)
help("orcutt")
help("cochrane.orcutt")
help("confint")
confint(model_CO,vcov(model_CO))
confint(model_CO)
confint(model_CO)["(unemp)",]
confint(model_CO)
model_CO <- cochrane.orcutt(q1e)
summary(model_CO)
exp(model_CO$coefficients)-1
0.139232-1.96*0.248314
0.139232+1.96*0.248314
q1e <- lm(log(carexp_adjusted)~unemp + unemp_lag1 + unemp_lag2 + year, data=at)
summary(q1e)
model_CO <- cochrane.orcutt(q1e)
summary(model_CO)
lm(log(carexp)~year,data=at)
q1j <- lm(log(carexp)~year,data=at)
summary(q1j)
at$lced <- q1j$residuals
View(at)
at$lced_lag1 <- c(NA, at$lced[-n])
head(at)
lm(lced~lced_lag1,data=at)
q1k <- lm(lced~lced_lag1,data=at)
summary(q1k)
confint(q1k)
lmar <- labour_market
modelQ3 <- lm(wage ~ ., data=lmar)
summary(modelQ3)
library(lmtest)
library(sandwich)
bptest(modelQ3)
vcov_robust <- vcovHC(modelQ3)
vcov_robust
stdErr_robust <- sqrt(diag(vcov_robust))
stdErr_robust
#Calculate the conventional standard error
#Just delete the HC in the vcovHC, so to get the conventional standarrd errors
vcov_conventional <- vcov(modelQ3)
stdErr_conventional <- sqrt(diag(vcov_conventional))
rbind(stdErr_conventional, stdErr_robust)
# Ways to display results with std errors
coeftest(modelQ3, vcov = vcov_robust)
# To see the confidence invertals
# 95% CI based on robust std. errors
confint(modelQ3, vcov = vcov_robust)
library(stargazer)
stargazer(
modelQ3, modelQ3, se = list(NULL, stdErr_robust), type = "text"
)
modelQ3 <- lm(wage ~ ., data=lmar)
summary(modelQ3)
help("one-tail")
help("hypothesis")
help(normal distribution)
0.02554*2
lmar$femaleXmarried <- lmar$female*lmar$married
model3b <- lm(wage~.,data=lmar)
summary(model3b)
bgtest(model3b)
confint(model3b)
linearHypothesis(model1, "femaleXmarried=0")
c(18,0,1,0,0,1,0,0)*model3b$coefficients
c(1,18,0,1,0,0,1,0,0)*model3b$coefficients
sum(1,18,0,1,0,0,1,0,0)*coef(model3b))
sum(18,0,1,0,0,1,0,0)*coef(model3b))
sum(c(18,0,1,0,0,1,0,0)*coef(model3b))
sum(c(1,18,0,1,0,0,1,0,0)*coef(model3b))
sum(c(1,18,0,1,0,0,1,0,0)*coef(model3b))
-20.7526029+18*1.7411167+1.8864791+1.9940948
-20.7526029+18*1.7411167+1.8864791+1.9940948
sum(-20.7526029+18*1.7411167+1.8864791+1.9940948)
library(dplyr)
library(ggplot2)
```{r, echo=FALSE}
```{r, echo=FALSE}
library(purrr)
# install.packages("tidyverse")
setwd("C:/Users/nade/Desktop/Data Analysis R")
### LOAD PACKAGE ###
library(tidyverse)
